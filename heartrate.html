<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Heart Rate Monitor</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #0f0f1a 0%, #1a1a2e 100%);
            color: #eee;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            touch-action: none;
        }
        h1 { margin-bottom: 5px; font-size: 1.5em; }
        .subtitle { color: #666; font-size: 0.85em; margin-bottom: 15px; text-align: center; }
        
        #video-container {
            position: relative;
            width: 100%;
            max-width: 350px;
            aspect-ratio: 1;
            background: #000;
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 15px;
        }
        video {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
        }
        #overlay {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
            pointer-events: none;
        }
        
        #roi-box {
            position: absolute;
            border: 2px solid rgba(100, 255, 100, 0.8);
            background: rgba(100, 255, 100, 0.15);
            border-radius: 4px;
            pointer-events: none;
            box-shadow: 0 0 10px rgba(100, 255, 100, 0.3);
        }
        
        #face-box {
            position: absolute;
            border: 1px dashed rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            pointer-events: none;
        }
        
        #bpm-display {
            font-size: 2.8em;
            font-weight: bold;
            color: #ff6b6b;
            text-shadow: 0 0 30px rgba(255, 107, 107, 0.5);
            margin: 5px 0;
            transition: color 0.3s;
        }
        #bpm-display.detecting { color: #ffaa6b; }
        #bpm-display.stable { color: #6bff6b; }
        #bpm-display span { font-size: 0.35em; color: #888; }
        
        #confidence {
            font-size: 0.8em;
            color: #666;
            margin-bottom: 10px;
        }
        
        #signal-container {
            width: 100%;
            max-width: 400px;
            height: 80px;
            background: rgba(255,255,255,0.05);
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 10px;
        }
        #signal-canvas { width: 100%; height: 100%; }
        
        #status {
            color: #888;
            font-size: 0.85em;
            text-align: center;
            margin-bottom: 15px;
            min-height: 1.2em;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            justify-content: center;
        }
        
        button {
            background: rgba(255, 107, 107, 0.2);
            border: 1px solid rgba(255, 107, 107, 0.5);
            color: #ff6b6b;
            padding: 10px 20px;
            border-radius: 8px;
            font-size: 0.9em;
            cursor: pointer;
            transition: all 0.2s;
        }
        button:hover { background: rgba(255, 107, 107, 0.3); }
        button:disabled { opacity: 0.4; cursor: not-allowed; }
        button.active { background: rgba(107, 255, 107, 0.2); border-color: rgba(107, 255, 107, 0.5); color: #6bff6b; }
        
        #instructions {
            position: absolute;
            top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0,0,0,0.85);
            padding: 20px;
            border-radius: 12px;
            text-align: center;
            z-index: 10;
        }
        #instructions.hidden { display: none; }
        
        .back-link {
            position: fixed;
            top: 15px;
            left: 15px;
            color: #666;
            text-decoration: none;
            font-size: 1.5em;
        }
        
    </style>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
</head>
<body>
    <a href="index.html" class="back-link">‚Üê</a>
    <h1>‚ù§Ô∏è Heart Rate Monitor</h1>
    
    <div id="video-container">
        <video id="video" autoplay playsinline></video>
        <canvas id="overlay"></canvas>
        <div id="face-box" style="display:none;"></div>
        <div id="roi-box" style="display:none;"></div>
        <div id="instructions">
            <p>Tap to start</p>
        </div>
    </div>
    
    <div id="bpm-display">-- <span>BPM</span></div>
    
    <div id="signal-container">
        <canvas id="signal-canvas"></canvas>
    </div>
    
    <div id="status">Tap to start camera</div>
    
    <div class="controls">
        <button id="reset-btn">Reset</button>
        <button id="torch-btn">üí°</button>
        <button id="amplify-btn">üîç Amplify</button>
    </div>

    <script>
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const overlayCtx = overlay.getContext('2d', { willReadFrequently: true });
        const signalCanvas = document.getElementById('signal-canvas');
        const signalCtx = signalCanvas.getContext('2d');
        const bpmDisplay = document.getElementById('bpm-display');
        const confidenceEl = document.getElementById('confidence');
        const statusEl = document.getElementById('status');
        const roiBox = document.getElementById('roi-box');
        const faceBox = document.getElementById('face-box');
        const instructions = document.getElementById('instructions');
        const resetBtn = document.getElementById('reset-btn');
        const torchBtn = document.getElementById('torch-btn');
        const amplifyBtn = document.getElementById('amplify-btn');
        const videoContainer = document.getElementById('video-container');
        
        let stream = null;
        let faceDetection = null;
        let currentFace = null;
        let roi = null;
        let rawSignal = [];
        let filteredSignal = [];
        let timestamps = [];
        let bpmHistory = [];
        let currentBPM = null;
        let isRunning = false;
        let torchOn = false;
        let amplifyMode = false;
        let colorBuffer = [];
        const COLOR_BUFFER_SIZE = 30;
        let smoothedROI = null;
        let prevGray = null;
        let trackPoints = null;
        const ROI_SMOOTHING = 0.4; // How fast to blend toward face detection
        
        const BUFFER_SIZE = 300;
        const MIN_HZ = 0.7;
        const MAX_HZ = 3.5;
        const BPM_SMOOTHING = 0.15;
        
        // Initialize face detection
        async function initFaceDetection() {
            faceDetection = new FaceDetection({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`
            });
            
            faceDetection.setOptions({
                model: 'short',
                minDetectionConfidence: 0.5
            });
            
            faceDetection.onResults(onFaceResults);
            await faceDetection.initialize();
        }
        
        function onFaceResults(results) {
            if (results.detections && results.detections.length > 0) {
                currentFace = results.detections[0];
            } else {
                currentFace = null;
            }
        }
        
        // Resize canvases
        function resizeCanvases() {
            const rect = videoContainer.getBoundingClientRect();
            overlay.width = rect.width;
            overlay.height = rect.height;
            signalCanvas.width = signalCanvas.parentElement.clientWidth;
            signalCanvas.height = signalCanvas.parentElement.clientHeight;
        }
        window.addEventListener('resize', resizeCanvases);
        
        // Start camera
        async function startCamera() {
            try {
                statusEl.textContent = 'Starting camera...';
                
                const constraints = {
                    video: {
                        facingMode: 'user',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                };
                
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                await video.play();
                
                instructions.classList.add('hidden');
                statusEl.textContent = 'Initializing face detection...';
                
                await initFaceDetection();
                
                resizeCanvases();
                isRunning = true;
                statusEl.textContent = 'Looking for face...';
                requestAnimationFrame(processFrame);
                
            } catch (err) {
                statusEl.textContent = 'Camera error: ' + err.message;
                console.error(err);
            }
        }
        
        // Toggle amplification mode
        amplifyBtn.addEventListener('click', () => {
            amplifyMode = !amplifyMode;
            amplifyBtn.classList.toggle('active', amplifyMode);
            colorBuffer = [];
            if (amplifyMode) {
                statusEl.textContent = 'Color amplification ON - watch for pulse!';
            }
        });
        
        // Toggle torch
        torchBtn.addEventListener('click', async () => {
            if (!stream) return;
            const track = stream.getVideoTracks()[0];
            const capabilities = track.getCapabilities();
            
            if (capabilities.torch) {
                torchOn = !torchOn;
                await track.applyConstraints({ advanced: [{ torch: torchOn }] });
                torchBtn.classList.toggle('active', torchOn);
            } else {
                statusEl.textContent = 'Torch not available';
            }
        });
        
        // Handle tap to start
        videoContainer.addEventListener('click', async () => {
            if (!stream) {
                await startCamera();
            }
        });
        
        // Reset
        resetBtn.addEventListener('click', () => {
            rawSignal = [];
            filteredSignal = [];
            timestamps = [];
            bpmHistory = [];
            currentBPM = null;
            smoothedROI = null;
            prevGray = null;
            trackPoints = null;
            bpmDisplay.innerHTML = '-- <span>BPM</span>';
            bpmDisplay.className = '';
            confidenceEl.textContent = '';
            statusEl.textContent = 'Looking for face...';
        });
        
        // Simple Lucas-Kanade optical flow for single point
        function trackPointLK(prevImg, currImg, px, py, winSize = 15) {
            const hw = Math.floor(winSize / 2);
            
            // Compute gradients at point in previous image
            let Ixx = 0, Iyy = 0, Ixy = 0, Ixt = 0, Iyt = 0;
            
            for (let dy = -hw; dy <= hw; dy++) {
                for (let dx = -hw; dx <= hw; dx++) {
                    const x = Math.floor(px) + dx;
                    const y = Math.floor(py) + dy;
                    
                    if (x < 1 || x >= prevImg.width - 1 || y < 1 || y >= prevImg.height - 1) continue;
                    
                    const idx = y * prevImg.width + x;
                    const idxL = idx - 1, idxR = idx + 1;
                    const idxU = idx - prevImg.width, idxD = idx + prevImg.width;
                    
                    // Spatial gradients (Sobel-ish)
                    const Ix = (prevImg.data[idxR] - prevImg.data[idxL]) / 2;
                    const Iy = (prevImg.data[idxD] - prevImg.data[idxU]) / 2;
                    // Temporal gradient
                    const It = currImg.data[idx] - prevImg.data[idx];
                    
                    Ixx += Ix * Ix;
                    Iyy += Iy * Iy;
                    Ixy += Ix * Iy;
                    Ixt += Ix * It;
                    Iyt += Iy * It;
                }
            }
            
            // Solve 2x2 system: [Ixx Ixy; Ixy Iyy] * [vx; vy] = -[Ixt; Iyt]
            const det = Ixx * Iyy - Ixy * Ixy;
            if (Math.abs(det) < 0.001) return { x: px, y: py, valid: false };
            
            const vx = -(Iyy * Ixt - Ixy * Iyt) / det;
            const vy = -(Ixx * Iyt - Ixy * Ixt) / det;
            
            // Reject large movements (likely tracking failure)
            if (Math.abs(vx) > 20 || Math.abs(vy) > 20) return { x: px, y: py, valid: false };
            
            return { x: px + vx, y: py + vy, valid: true };
        }
        
        // Convert to grayscale
        function toGrayscale(imageData) {
            const gray = { width: imageData.width, height: imageData.height, data: new Float32Array(imageData.width * imageData.height) };
            for (let i = 0; i < imageData.data.length; i += 4) {
                gray.data[i / 4] = imageData.data[i] * 0.299 + imageData.data[i + 1] * 0.587 + imageData.data[i + 2] * 0.114;
            }
            return gray;
        }
        
        // Get forehead ROI from face detection
        function getForeheadROI(face, containerW, containerH) {
            const box = face.boundingBox;
            
            // Face box in normalized coords (0-1)
            const faceX = box.xCenter - box.width / 2;
            const faceY = box.yCenter - box.height / 2;
            const faceW = box.width;
            const faceH = box.height;
            
            // Mirror X for display (camera is mirrored)
            const mirrorX = 1 - faceX - faceW;
            
            // Forehead region: center of forehead, well above eyebrows
            const roiW = faceW * 0.45;
            const roiH = faceH * 0.1;
            const roiX = mirrorX + (faceW - roiW) / 2;
            const roiY = faceY - faceH * 0.1; // Above the face box
            
            return {
                x: roiX * containerW,
                y: roiY * containerH,
                width: roiW * containerW,
                height: roiH * containerH,
                // For face box display
                faceX: mirrorX * containerW,
                faceY: faceY * containerH,
                faceW: faceW * containerW,
                faceH: faceH * containerH
            };
        }
        
        // Template matching for tracking
        function matchTemplate(imageData, template, searchX, searchY, searchW, searchH) {
            if (!template) return null;
            
            const tw = template.width;
            const th = template.height;
            let bestX = searchX, bestY = searchY;
            let bestScore = Infinity;
            
            const step = 2; // Search every 2 pixels for speed
            
            for (let y = searchY; y < searchY + searchH - th; y += step) {
                for (let x = searchX; x < searchX + searchW - tw; x += step) {
                    let score = 0;
                    let count = 0;
                    
                    // Sample pixels (not all, for speed)
                    for (let ty = 0; ty < th; ty += 3) {
                        for (let tx = 0; tx < tw; tx += 3) {
                            const imgIdx = ((y + ty) * imageData.width + (x + tx)) * 4;
                            const tplIdx = (ty * tw + tx) * 4;
                            
                            // Compare green channel primarily (best for PPG)
                            const diff = imageData.data[imgIdx + 1] - template.data[tplIdx + 1];
                            score += diff * diff;
                            count++;
                        }
                    }
                    
                    score /= count;
                    if (score < bestScore) {
                        bestScore = score;
                        bestX = x;
                        bestY = y;
                    }
                }
            }
            
            return { x: bestX, y: bestY, score: bestScore };
        }
        
        // Extract template from image data
        function extractTemplate(imageData, x, y, w, h) {
            const template = {
                width: Math.floor(w),
                height: Math.floor(h),
                data: new Uint8ClampedArray(Math.floor(w) * Math.floor(h) * 4)
            };
            
            for (let ty = 0; ty < template.height; ty++) {
                for (let tx = 0; tx < template.width; tx++) {
                    const srcIdx = ((Math.floor(y) + ty) * imageData.width + Math.floor(x) + tx) * 4;
                    const dstIdx = (ty * template.width + tx) * 4;
                    template.data[dstIdx] = imageData.data[srcIdx];
                    template.data[dstIdx + 1] = imageData.data[srcIdx + 1];
                    template.data[dstIdx + 2] = imageData.data[srcIdx + 2];
                    template.data[dstIdx + 3] = imageData.data[srcIdx + 3];
                }
            }
            
            return template;
        }
        
        // Process video frame
        let frameCount = 0;
        async function processFrame() {
            if (!isRunning) return;
            
            const containerW = overlay.width;
            const containerH = overlay.height;
            
            // Draw video to canvas (mirrored to match CSS video display)
            overlayCtx.save();
            overlayCtx.translate(containerW, 0);
            overlayCtx.scale(-1, 1);
            overlayCtx.drawImage(video, 0, 0, containerW, containerH);
            overlayCtx.restore();
            
            // Run face detection every 5 frames
            if (frameCount % 5 === 0) {
                await faceDetection.send({ image: video });
            }
            frameCount++;
            
            const imageData = overlayCtx.getImageData(0, 0, containerW, containerH);
            const currGray = toGrayscale(imageData);
            
            // Track ROI with optical flow between face detections
            if (prevGray && smoothedROI && trackPoints) {
                let dx = 0, dy = 0, validCount = 0;
                
                for (const pt of trackPoints) {
                    const tracked = trackPointLK(prevGray, currGray, pt.x, pt.y);
                    if (tracked.valid) {
                        dx += tracked.x - pt.x;
                        dy += tracked.y - pt.y;
                        pt.x = tracked.x;
                        pt.y = tracked.y;
                        validCount++;
                    }
                }
                
                if (validCount > 2) {
                    dx /= validCount;
                    dy /= validCount;
                    smoothedROI.x += dx;
                    smoothedROI.y += dy;
                }
            }
            
            prevGray = currGray;
            
            if (currentFace) {
                roi = getForeheadROI(currentFace, containerW, containerH);
                
                // Show face box
                faceBox.style.display = 'block';
                faceBox.style.left = roi.faceX + 'px';
                faceBox.style.top = roi.faceY + 'px';
                faceBox.style.width = roi.faceW + 'px';
                faceBox.style.height = roi.faceH + 'px';
                
                // Smooth ROI position to reduce jitter
                if (smoothedROI === null) {
                    smoothedROI = { ...roi };
                } else {
                    // Blend optical flow tracked position toward face detection
                    smoothedROI.x = smoothedROI.x * (1 - ROI_SMOOTHING) + roi.x * ROI_SMOOTHING;
                    smoothedROI.y = smoothedROI.y * (1 - ROI_SMOOTHING) + roi.y * ROI_SMOOTHING;
                    smoothedROI.width = smoothedROI.width * (1 - ROI_SMOOTHING) + roi.width * ROI_SMOOTHING;
                    smoothedROI.height = smoothedROI.height * (1 - ROI_SMOOTHING) + roi.height * ROI_SMOOTHING;
                }
                
                // Update tracking points periodically
                if (frameCount % 10 === 0) {
                    trackPoints = [
                        { x: smoothedROI.x + smoothedROI.width * 0.25, y: smoothedROI.y + smoothedROI.height * 0.5 },
                        { x: smoothedROI.x + smoothedROI.width * 0.5, y: smoothedROI.y + smoothedROI.height * 0.5 },
                        { x: smoothedROI.x + smoothedROI.width * 0.75, y: smoothedROI.y + smoothedROI.height * 0.5 },
                        { x: smoothedROI.x + smoothedROI.width * 0.5, y: smoothedROI.y + smoothedROI.height * 0.25 },
                        { x: smoothedROI.x + smoothedROI.width * 0.5, y: smoothedROI.y + smoothedROI.height * 0.75 },
                    ];
                }
                
                // Use smoothed position for display and sampling
                const displayROI = smoothedROI;
                
                // Show ROI box
                roiBox.style.display = 'block';
                roiBox.style.left = displayROI.x + 'px';
                roiBox.style.top = displayROI.y + 'px';
                roiBox.style.width = displayROI.width + 'px';
                roiBox.style.height = displayROI.height + 'px';
                
                // Sample ROI - focus on center for best signal
                // Clamp to canvas bounds
                const roiX = Math.max(0, displayROI.x);
                const roiY = Math.max(0, displayROI.y);
                const roiRight = Math.min(containerW, displayROI.x + displayROI.width);
                const roiBottom = Math.min(containerH, displayROI.y + displayROI.height);
                
                const sampleX = Math.floor(roiX + (roiRight - roiX) * 0.2);
                const sampleY = Math.floor(roiY + (roiBottom - roiY) * 0.2);
                const sampleW = Math.floor((roiRight - roiX) * 0.6);
                const sampleH = Math.floor((roiBottom - roiY) * 0.6);
                
                let greenSum = 0, redSum = 0, count = 0;
                
                for (let y = sampleY; y < sampleY + sampleH && y < containerH; y++) {
                    for (let x = sampleX; x < sampleX + sampleW && x < containerW; x++) {
                        const idx = (y * containerW + x) * 4;
                        redSum += imageData.data[idx];
                        greenSum += imageData.data[idx + 1];
                        count++;
                    }
                }
                
                if (count > 0) {
                    // Use green channel, normalize by red to reduce lighting effects
                    const green = greenSum / count;
                    const red = redSum / count;
                    const normalized = green / (red + 0.001);
                    
                    const now = performance.now();
                    rawSignal.push(normalized);
                    timestamps.push(now);
                    
                    while (rawSignal.length > BUFFER_SIZE) {
                        rawSignal.shift();
                        timestamps.shift();
                    }
                    
                    if (rawSignal.length >= 90) {
                        processSignal();
                    } else {
                        statusEl.textContent = `Collecting data... ${Math.round(rawSignal.length / 90 * 100)}%`;
                    }
                }
            } else {
                faceBox.style.display = 'none';
                roiBox.style.display = 'none';
                statusEl.textContent = 'Looking for face...';
                smoothedROI = null;
                prevGray = null;
                trackPoints = null;
            }
            
            // Clear overlay for next frame (or show amplified if enabled)
            if (amplifyMode && currentFace) {
                // Simplified Eulerian magnification - amplify color changes
                const ampFactor = 50; // How much to amplify
                
                // Store current frame colors in buffer
                colorBuffer.push(imageData);
                if (colorBuffer.length > COLOR_BUFFER_SIZE) colorBuffer.shift();
                
                if (colorBuffer.length >= 10) {
                    // Compute temporal average
                    const avg = new Float32Array(imageData.data.length);
                    for (const frame of colorBuffer) {
                        for (let i = 0; i < frame.data.length; i++) {
                            avg[i] += frame.data[i] / colorBuffer.length;
                        }
                    }
                    
                    // Amplify difference from average (bandpass would be better but this works)
                    const amplified = overlayCtx.createImageData(containerW, containerH);
                    for (let i = 0; i < imageData.data.length; i += 4) {
                        // Amplify green channel most (best for PPG)
                        const diffR = (imageData.data[i] - avg[i]) * ampFactor * 0.5;
                        const diffG = (imageData.data[i + 1] - avg[i + 1]) * ampFactor;
                        const diffB = (imageData.data[i + 2] - avg[i + 2]) * ampFactor * 0.5;
                        
                        amplified.data[i] = Math.max(0, Math.min(255, imageData.data[i] + diffR));
                        amplified.data[i + 1] = Math.max(0, Math.min(255, imageData.data[i + 1] + diffG));
                        amplified.data[i + 2] = Math.max(0, Math.min(255, imageData.data[i + 2] + diffB));
                        amplified.data[i + 3] = 255;
                    }
                    
                    overlayCtx.putImageData(amplified, 0, 0);
                } else {
                    overlayCtx.clearRect(0, 0, containerW, containerH);
                }
            } else {
                overlayCtx.clearRect(0, 0, containerW, containerH);
            }
            
            drawSignal();
            requestAnimationFrame(processFrame);
        }
        
        // Butterworth bandpass filter coefficients (pre-calculated for ~30fps, 0.7-3.5Hz)
        function butterworthBandpass(signal, sampleRate) {
            // Simple IIR bandpass approximation
            const lowCutoff = MIN_HZ / (sampleRate / 2);
            const highCutoff = MAX_HZ / (sampleRate / 2);
            
            // Two-pass moving average for bandpass effect
            const lowPassSize = Math.max(2, Math.round(sampleRate / MAX_HZ / 2));
            const highPassSize = Math.max(3, Math.round(sampleRate / MIN_HZ));
            
            // Low pass
            let lowPassed = [];
            for (let i = 0; i < signal.length; i++) {
                const start = Math.max(0, i - lowPassSize);
                const slice = signal.slice(start, i + 1);
                lowPassed.push(slice.reduce((a, b) => a + b, 0) / slice.length);
            }
            
            // High pass (subtract very slow moving average)
            let result = [];
            for (let i = 0; i < lowPassed.length; i++) {
                const start = Math.max(0, i - highPassSize);
                const slice = lowPassed.slice(start, i + 1);
                const slowAvg = slice.reduce((a, b) => a + b, 0) / slice.length;
                result.push(lowPassed[i] - slowAvg);
            }
            
            return result;
        }
        
        function processSignal() {
            const duration = (timestamps[timestamps.length - 1] - timestamps[0]) / 1000;
            const sampleRate = rawSignal.length / duration;
            
            // Detrend
            const detrended = detrend(rawSignal);
            
            // Bandpass filter
            filteredSignal = butterworthBandpass(detrended, sampleRate);
            
            // Find BPM using autocorrelation (more robust than peak detection)
            const bpm = estimateBPMAutocorr(filteredSignal, sampleRate);
            
            if (bpm && bpm >= 42 && bpm <= 200) {
                bpmHistory.push(bpm);
                if (bpmHistory.length > 10) bpmHistory.shift();
                
                // Median filter for stability
                const sorted = [...bpmHistory].sort((a, b) => a - b);
                const median = sorted[Math.floor(sorted.length / 2)];
                
                if (currentBPM === null) {
                    currentBPM = median;
                } else {
                    currentBPM = currentBPM * (1 - BPM_SMOOTHING) + median * BPM_SMOOTHING;
                }
                
                bpmDisplay.innerHTML = Math.round(currentBPM) + ' <span>BPM</span>';
                
                // Confidence based on signal quality
                const variance = calcVariance(bpmHistory);
                const cv = Math.sqrt(variance) / (currentBPM || 1);
                
                if (cv < 0.05) {
                    bpmDisplay.className = 'stable';
                    confidenceEl.textContent = '‚óè High confidence';
                    confidenceEl.style.color = '#6bff6b';
                } else if (cv < 0.15) {
                    bpmDisplay.className = 'detecting';
                    confidenceEl.textContent = '‚óè Detecting...';
                    confidenceEl.style.color = '#ffaa6b';
                } else {
                    bpmDisplay.className = '';
                    confidenceEl.textContent = '‚óè Low confidence';
                    confidenceEl.style.color = '#ff6b6b';
                }
                
                statusEl.textContent = `Sample rate: ${sampleRate.toFixed(1)} Hz`;
            }
        }
        
        function calcVariance(arr) {
            if (arr.length < 2) return 0;
            const mean = arr.reduce((a, b) => a + b, 0) / arr.length;
            return arr.reduce((sum, val) => sum + (val - mean) ** 2, 0) / arr.length;
        }
        
        function detrend(signal) {
            const n = signal.length;
            let sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
            for (let i = 0; i < n; i++) {
                sumX += i;
                sumY += signal[i];
                sumXY += i * signal[i];
                sumX2 += i * i;
            }
            const slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
            const intercept = (sumY - slope * sumX) / n;
            return signal.map((v, i) => v - (slope * i + intercept));
        }
        
        // Autocorrelation-based BPM estimation
        function estimateBPMAutocorr(signal, sampleRate) {
            const n = signal.length;
            if (n < 60) return null;
            
            // Min/max lag for 42-200 BPM
            const minLag = Math.floor(sampleRate * 60 / 200);
            const maxLag = Math.ceil(sampleRate * 60 / 42);
            
            let bestLag = minLag;
            let bestCorr = -Infinity;
            
            // Compute autocorrelation
            for (let lag = minLag; lag <= Math.min(maxLag, n / 2); lag++) {
                let corr = 0;
                let count = 0;
                for (let i = 0; i < n - lag; i++) {
                    corr += signal[i] * signal[i + lag];
                    count++;
                }
                corr /= count;
                
                if (corr > bestCorr) {
                    bestCorr = corr;
                    bestLag = lag;
                }
            }
            
            const period = bestLag / sampleRate;
            return 60 / period;
        }
        
        // Draw signal visualization
        function drawSignal() {
            const ctx = signalCtx;
            const w = signalCanvas.width;
            const h = signalCanvas.height;
            
            ctx.fillStyle = 'rgba(15, 15, 26, 0.4)';
            ctx.fillRect(0, 0, w, h);
            
            const signal = filteredSignal.length > 0 ? filteredSignal : rawSignal;
            if (signal.length < 2) return;
            
            const min = Math.min(...signal);
            const max = Math.max(...signal);
            const range = max - min || 1;
            
            // Waveform
            ctx.beginPath();
            ctx.strokeStyle = '#ff6b6b';
            ctx.lineWidth = 2;
            
            for (let i = 0; i < signal.length; i++) {
                const x = (i / signal.length) * w;
                const y = h - ((signal[i] - min) / range) * h * 0.8 - h * 0.1;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            ctx.stroke();
            
            // Zero line
            ctx.strokeStyle = 'rgba(255,255,255,0.1)';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(0, h / 2);
            ctx.lineTo(w, h / 2);
            ctx.stroke();
        }
        
        // Initial setup
        resizeCanvases();
        drawSignal();
    </script>
</body>
</html>
