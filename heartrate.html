<!DOCTYPE html>
<html>
<head>
    <title>Heart Rate Monitor</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #0f0f1a 0%, #1a1a2e 100%);
            color: #eee;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            touch-action: none;
        }
        h1 { margin-bottom: 5px; font-size: 1.5em; }
        .subtitle { color: #666; font-size: 0.85em; margin-bottom: 15px; text-align: center; }
        
        #video-container {
            position: relative;
            width: 100%;
            max-width: 350px;
            aspect-ratio: 1;
            background: #000;
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 15px;
        }
        video {
            position: absolute;
            top: 50%; left: 50%;
            transform: translate(-50%, -50%) scaleX(-1);
            min-width: 100%;
            min-height: 100%;
        }
        #overlay {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
            pointer-events: none;
        }
        
        #roi-box {
            position: absolute;
            border: 2px solid rgba(100, 255, 100, 0.8);
            background: rgba(100, 255, 100, 0.15);
            border-radius: 4px;
            pointer-events: none;
            box-shadow: 0 0 10px rgba(100, 255, 100, 0.3);
        }
        
        #face-box {
            position: absolute;
            border: 1px dashed rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            pointer-events: none;
        }
        
        #bpm-display {
            font-size: 3.5em;
            font-weight: bold;
            color: #ff6b6b;
            text-shadow: 0 0 30px rgba(255, 107, 107, 0.5);
            margin: 10px 0;
            transition: color 0.3s;
        }
        #bpm-display.detecting { color: #ffaa6b; }
        #bpm-display.stable { color: #6bff6b; }
        #bpm-display span { font-size: 0.35em; color: #888; }
        
        #confidence {
            font-size: 0.8em;
            color: #666;
            margin-bottom: 10px;
        }
        
        #signal-container {
            width: 100%;
            max-width: 400px;
            height: 120px;
            background: rgba(255,255,255,0.05);
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 15px;
        }
        #signal-canvas { width: 100%; height: 100%; }
        
        #status {
            color: #888;
            font-size: 0.85em;
            text-align: center;
            margin-bottom: 15px;
            min-height: 1.2em;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            justify-content: center;
        }
        
        button {
            background: rgba(255, 107, 107, 0.2);
            border: 1px solid rgba(255, 107, 107, 0.5);
            color: #ff6b6b;
            padding: 10px 20px;
            border-radius: 8px;
            font-size: 0.9em;
            cursor: pointer;
            transition: all 0.2s;
        }
        button:hover { background: rgba(255, 107, 107, 0.3); }
        button:disabled { opacity: 0.4; cursor: not-allowed; }
        button.active { background: rgba(107, 255, 107, 0.2); border-color: rgba(107, 255, 107, 0.5); color: #6bff6b; }
        
        #instructions {
            position: absolute;
            top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0,0,0,0.85);
            padding: 20px;
            border-radius: 12px;
            text-align: center;
            z-index: 10;
        }
        #instructions.hidden { display: none; }
        
        .back-link {
            position: fixed;
            top: 15px;
            left: 15px;
            color: #666;
            text-decoration: none;
            font-size: 1.5em;
        }
        
        #zoom-control {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
        }
        #zoom-control input {
            width: 100px;
            accent-color: #ff6b6b;
        }
        #zoom-control label {
            color: #888;
            font-size: 0.85em;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
</head>
<body>
    <a href="index.html" class="back-link">‚Üê</a>
    <h1>‚ù§Ô∏è Heart Rate Monitor</h1>
    <p class="subtitle">Face detection + forehead tracking</p>
    
    <div id="video-container">
        <video id="video" autoplay playsinline></video>
        <canvas id="overlay"></canvas>
        <div id="face-box" style="display:none;"></div>
        <div id="roi-box" style="display:none;"></div>
        <div id="instructions">
            <p>Tap to start</p>
        </div>
    </div>
    
    <div id="zoom-control">
        <label>Zoom:</label>
        <input type="range" id="zoom-slider" min="1" max="3" step="0.1" value="1.5">
        <span id="zoom-value">1.5x</span>
    </div>
    
    <div id="bpm-display">-- <span>BPM</span></div>
    <div id="confidence"></div>
    
    <div id="signal-container">
        <canvas id="signal-canvas"></canvas>
    </div>
    
    <div id="status">Tap to start camera</div>
    
    <div class="controls">
        <button id="reset-btn">Reset</button>
        <button id="torch-btn">üí° Light</button>
    </div>

    <script>
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const overlayCtx = overlay.getContext('2d', { willReadFrequently: true });
        const signalCanvas = document.getElementById('signal-canvas');
        const signalCtx = signalCanvas.getContext('2d');
        const bpmDisplay = document.getElementById('bpm-display');
        const confidenceEl = document.getElementById('confidence');
        const statusEl = document.getElementById('status');
        const roiBox = document.getElementById('roi-box');
        const faceBox = document.getElementById('face-box');
        const instructions = document.getElementById('instructions');
        const resetBtn = document.getElementById('reset-btn');
        const torchBtn = document.getElementById('torch-btn');
        const zoomSlider = document.getElementById('zoom-slider');
        const zoomValue = document.getElementById('zoom-value');
        const videoContainer = document.getElementById('video-container');
        
        let stream = null;
        let faceDetection = null;
        let currentFace = null;
        let roi = null;
        let rawSignal = [];
        let filteredSignal = [];
        let timestamps = [];
        let bpmHistory = [];
        let currentBPM = null;
        let isRunning = false;
        let zoom = 1.5;
        let torchOn = false;
        let lastTemplate = null;
        let templatePos = null;
        
        const BUFFER_SIZE = 300;
        const MIN_HZ = 0.7;
        const MAX_HZ = 3.5;
        const BPM_SMOOTHING = 0.15;
        
        // Initialize face detection
        async function initFaceDetection() {
            faceDetection = new FaceDetection({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`
            });
            
            faceDetection.setOptions({
                model: 'short',
                minDetectionConfidence: 0.5
            });
            
            faceDetection.onResults(onFaceResults);
            await faceDetection.initialize();
        }
        
        function onFaceResults(results) {
            if (results.detections && results.detections.length > 0) {
                currentFace = results.detections[0];
            } else {
                currentFace = null;
            }
        }
        
        // Resize canvases
        function resizeCanvases() {
            const rect = videoContainer.getBoundingClientRect();
            overlay.width = rect.width;
            overlay.height = rect.height;
            signalCanvas.width = signalCanvas.parentElement.clientWidth;
            signalCanvas.height = signalCanvas.parentElement.clientHeight;
        }
        window.addEventListener('resize', resizeCanvases);
        
        // Zoom control
        zoomSlider.addEventListener('input', (e) => {
            zoom = parseFloat(e.target.value);
            zoomValue.textContent = zoom.toFixed(1) + 'x';
            video.style.transform = `translate(-50%, -50%) scaleX(-${zoom}) scaleY(${zoom})`;
        });
        
        // Start camera
        async function startCamera() {
            try {
                statusEl.textContent = 'Starting camera...';
                
                const constraints = {
                    video: {
                        facingMode: 'user',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                };
                
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                await video.play();
                
                // Apply initial zoom
                video.style.transform = `translate(-50%, -50%) scaleX(-${zoom}) scaleY(${zoom})`;
                
                instructions.classList.add('hidden');
                statusEl.textContent = 'Initializing face detection...';
                
                await initFaceDetection();
                
                resizeCanvases();
                isRunning = true;
                statusEl.textContent = 'Looking for face...';
                requestAnimationFrame(processFrame);
                
            } catch (err) {
                statusEl.textContent = 'Camera error: ' + err.message;
                console.error(err);
            }
        }
        
        // Toggle torch
        torchBtn.addEventListener('click', async () => {
            if (!stream) return;
            const track = stream.getVideoTracks()[0];
            const capabilities = track.getCapabilities();
            
            if (capabilities.torch) {
                torchOn = !torchOn;
                await track.applyConstraints({ advanced: [{ torch: torchOn }] });
                torchBtn.classList.toggle('active', torchOn);
            } else {
                statusEl.textContent = 'Torch not available';
            }
        });
        
        // Handle tap to start
        videoContainer.addEventListener('click', async () => {
            if (!stream) {
                await startCamera();
            }
        });
        
        // Reset
        resetBtn.addEventListener('click', () => {
            rawSignal = [];
            filteredSignal = [];
            timestamps = [];
            bpmHistory = [];
            currentBPM = null;
            lastTemplate = null;
            templatePos = null;
            bpmDisplay.innerHTML = '-- <span>BPM</span>';
            bpmDisplay.className = '';
            confidenceEl.textContent = '';
            statusEl.textContent = 'Looking for face...';
        });
        
        // Get forehead ROI from face detection
        function getForeheadROI(face, containerW, containerH) {
            const box = face.boundingBox;
            
            // Face box in normalized coords
            const faceX = box.xCenter - box.width / 2;
            const faceY = box.yCenter - box.height / 2;
            
            // Forehead is upper portion of face, centered
            // Account for zoom: the visible area is 1/zoom of the video
            const visibleW = 1 / zoom;
            const visibleH = 1 / zoom;
            const offsetX = (1 - visibleW) / 2;
            const offsetY = (1 - visibleH) / 2;
            
            // Transform face coords to zoomed view
            const adjX = (faceX - offsetX) / visibleW;
            const adjY = (faceY - offsetY) / visibleH;
            const adjW = box.width / visibleW;
            const adjH = box.height / visibleH;
            
            // Mirror X for display (camera is mirrored)
            const mirrorX = 1 - adjX - adjW;
            
            // Forehead region: top 25% of face, middle 40%
            const roiW = adjW * 0.4;
            const roiH = adjH * 0.2;
            const roiX = mirrorX + (adjW - roiW) / 2;
            const roiY = adjY + adjH * 0.08;
            
            return {
                x: roiX * containerW,
                y: roiY * containerH,
                width: roiW * containerW,
                height: roiH * containerH,
                // For face box display
                faceX: mirrorX * containerW,
                faceY: adjY * containerH,
                faceW: adjW * containerW,
                faceH: adjH * containerH
            };
        }
        
        // Template matching for tracking
        function matchTemplate(imageData, template, searchX, searchY, searchW, searchH) {
            if (!template) return null;
            
            const tw = template.width;
            const th = template.height;
            let bestX = searchX, bestY = searchY;
            let bestScore = Infinity;
            
            const step = 2; // Search every 2 pixels for speed
            
            for (let y = searchY; y < searchY + searchH - th; y += step) {
                for (let x = searchX; x < searchX + searchW - tw; x += step) {
                    let score = 0;
                    let count = 0;
                    
                    // Sample pixels (not all, for speed)
                    for (let ty = 0; ty < th; ty += 3) {
                        for (let tx = 0; tx < tw; tx += 3) {
                            const imgIdx = ((y + ty) * imageData.width + (x + tx)) * 4;
                            const tplIdx = (ty * tw + tx) * 4;
                            
                            // Compare green channel primarily (best for PPG)
                            const diff = imageData.data[imgIdx + 1] - template.data[tplIdx + 1];
                            score += diff * diff;
                            count++;
                        }
                    }
                    
                    score /= count;
                    if (score < bestScore) {
                        bestScore = score;
                        bestX = x;
                        bestY = y;
                    }
                }
            }
            
            return { x: bestX, y: bestY, score: bestScore };
        }
        
        // Extract template from image data
        function extractTemplate(imageData, x, y, w, h) {
            const template = {
                width: Math.floor(w),
                height: Math.floor(h),
                data: new Uint8ClampedArray(Math.floor(w) * Math.floor(h) * 4)
            };
            
            for (let ty = 0; ty < template.height; ty++) {
                for (let tx = 0; tx < template.width; tx++) {
                    const srcIdx = ((Math.floor(y) + ty) * imageData.width + Math.floor(x) + tx) * 4;
                    const dstIdx = (ty * template.width + tx) * 4;
                    template.data[dstIdx] = imageData.data[srcIdx];
                    template.data[dstIdx + 1] = imageData.data[srcIdx + 1];
                    template.data[dstIdx + 2] = imageData.data[srcIdx + 2];
                    template.data[dstIdx + 3] = imageData.data[srcIdx + 3];
                }
            }
            
            return template;
        }
        
        // Process video frame
        let frameCount = 0;
        async function processFrame() {
            if (!isRunning) return;
            
            const containerW = overlay.width;
            const containerH = overlay.height;
            
            // Draw video to canvas
            overlayCtx.save();
            overlayCtx.translate(containerW, 0);
            overlayCtx.scale(-zoom, zoom);
            const offsetX = (video.videoWidth * (1 - 1/zoom)) / 2;
            const offsetY = (video.videoHeight * (1 - 1/zoom)) / 2;
            overlayCtx.drawImage(video, 
                -offsetX, -offsetY,
                video.videoWidth, video.videoHeight,
                0, 0,
                containerW / zoom, containerH / zoom
            );
            overlayCtx.restore();
            
            // Run face detection every 5 frames
            if (frameCount % 5 === 0) {
                await faceDetection.send({ image: video });
            }
            frameCount++;
            
            const imageData = overlayCtx.getImageData(0, 0, containerW, containerH);
            
            if (currentFace) {
                roi = getForeheadROI(currentFace, containerW, containerH);
                
                // Show face box
                faceBox.style.display = 'block';
                faceBox.style.left = roi.faceX + 'px';
                faceBox.style.top = roi.faceY + 'px';
                faceBox.style.width = roi.faceW + 'px';
                faceBox.style.height = roi.faceH + 'px';
                
                // Template tracking for stability
                if (lastTemplate && templatePos) {
                    const searchMargin = 20;
                    const match = matchTemplate(
                        imageData, lastTemplate,
                        Math.max(0, templatePos.x - searchMargin),
                        Math.max(0, templatePos.y - searchMargin),
                        Math.min(lastTemplate.width + searchMargin * 2, containerW - templatePos.x + searchMargin),
                        Math.min(lastTemplate.height + searchMargin * 2, containerH - templatePos.y + searchMargin)
                    );
                    
                    if (match && match.score < 1000) {
                        // Blend tracked position with detected position
                        roi.x = roi.x * 0.3 + match.x * 0.7;
                        roi.y = roi.y * 0.3 + match.y * 0.7;
                    }
                }
                
                // Update template periodically
                if (frameCount % 30 === 0 && roi.width > 10 && roi.height > 10) {
                    lastTemplate = extractTemplate(imageData, roi.x, roi.y, roi.width, roi.height);
                    templatePos = { x: roi.x, y: roi.y };
                }
                
                // Show ROI box
                roiBox.style.display = 'block';
                roiBox.style.left = roi.x + 'px';
                roiBox.style.top = roi.y + 'px';
                roiBox.style.width = roi.width + 'px';
                roiBox.style.height = roi.height + 'px';
                
                // Sample ROI - focus on center for best signal
                const sampleX = Math.floor(roi.x + roi.width * 0.2);
                const sampleY = Math.floor(roi.y + roi.height * 0.2);
                const sampleW = Math.floor(roi.width * 0.6);
                const sampleH = Math.floor(roi.height * 0.6);
                
                let greenSum = 0, redSum = 0, count = 0;
                
                for (let y = sampleY; y < sampleY + sampleH && y < containerH; y++) {
                    for (let x = sampleX; x < sampleX + sampleW && x < containerW; x++) {
                        const idx = (y * containerW + x) * 4;
                        redSum += imageData.data[idx];
                        greenSum += imageData.data[idx + 1];
                        count++;
                    }
                }
                
                if (count > 0) {
                    // Use green channel, normalize by red to reduce lighting effects
                    const green = greenSum / count;
                    const red = redSum / count;
                    const normalized = green / (red + 0.001);
                    
                    const now = performance.now();
                    rawSignal.push(normalized);
                    timestamps.push(now);
                    
                    while (rawSignal.length > BUFFER_SIZE) {
                        rawSignal.shift();
                        timestamps.shift();
                    }
                    
                    if (rawSignal.length >= 90) {
                        processSignal();
                    } else {
                        statusEl.textContent = `Collecting data... ${Math.round(rawSignal.length / 90 * 100)}%`;
                    }
                }
            } else {
                faceBox.style.display = 'none';
                roiBox.style.display = 'none';
                statusEl.textContent = 'Looking for face...';
                lastTemplate = null;
                templatePos = null;
            }
            
            // Clear overlay for next frame
            overlayCtx.clearRect(0, 0, containerW, containerH);
            
            drawSignal();
            requestAnimationFrame(processFrame);
        }
        
        // Butterworth bandpass filter coefficients (pre-calculated for ~30fps, 0.7-3.5Hz)
        function butterworthBandpass(signal, sampleRate) {
            // Simple IIR bandpass approximation
            const lowCutoff = MIN_HZ / (sampleRate / 2);
            const highCutoff = MAX_HZ / (sampleRate / 2);
            
            // Two-pass moving average for bandpass effect
            const lowPassSize = Math.max(2, Math.round(sampleRate / MAX_HZ / 2));
            const highPassSize = Math.max(3, Math.round(sampleRate / MIN_HZ));
            
            // Low pass
            let lowPassed = [];
            for (let i = 0; i < signal.length; i++) {
                const start = Math.max(0, i - lowPassSize);
                const slice = signal.slice(start, i + 1);
                lowPassed.push(slice.reduce((a, b) => a + b, 0) / slice.length);
            }
            
            // High pass (subtract very slow moving average)
            let result = [];
            for (let i = 0; i < lowPassed.length; i++) {
                const start = Math.max(0, i - highPassSize);
                const slice = lowPassed.slice(start, i + 1);
                const slowAvg = slice.reduce((a, b) => a + b, 0) / slice.length;
                result.push(lowPassed[i] - slowAvg);
            }
            
            return result;
        }
        
        function processSignal() {
            const duration = (timestamps[timestamps.length - 1] - timestamps[0]) / 1000;
            const sampleRate = rawSignal.length / duration;
            
            // Detrend
            const detrended = detrend(rawSignal);
            
            // Bandpass filter
            filteredSignal = butterworthBandpass(detrended, sampleRate);
            
            // Find BPM using autocorrelation (more robust than peak detection)
            const bpm = estimateBPMAutocorr(filteredSignal, sampleRate);
            
            if (bpm && bpm >= 42 && bpm <= 200) {
                bpmHistory.push(bpm);
                if (bpmHistory.length > 10) bpmHistory.shift();
                
                // Median filter for stability
                const sorted = [...bpmHistory].sort((a, b) => a - b);
                const median = sorted[Math.floor(sorted.length / 2)];
                
                if (currentBPM === null) {
                    currentBPM = median;
                } else {
                    currentBPM = currentBPM * (1 - BPM_SMOOTHING) + median * BPM_SMOOTHING;
                }
                
                bpmDisplay.innerHTML = Math.round(currentBPM) + ' <span>BPM</span>';
                
                // Confidence based on signal quality
                const variance = calcVariance(bpmHistory);
                const cv = Math.sqrt(variance) / (currentBPM || 1);
                
                if (cv < 0.05) {
                    bpmDisplay.className = 'stable';
                    confidenceEl.textContent = '‚óè High confidence';
                    confidenceEl.style.color = '#6bff6b';
                } else if (cv < 0.15) {
                    bpmDisplay.className = 'detecting';
                    confidenceEl.textContent = '‚óè Detecting...';
                    confidenceEl.style.color = '#ffaa6b';
                } else {
                    bpmDisplay.className = '';
                    confidenceEl.textContent = '‚óè Low confidence';
                    confidenceEl.style.color = '#ff6b6b';
                }
                
                statusEl.textContent = `Sample rate: ${sampleRate.toFixed(1)} Hz`;
            }
        }
        
        function calcVariance(arr) {
            if (arr.length < 2) return 0;
            const mean = arr.reduce((a, b) => a + b, 0) / arr.length;
            return arr.reduce((sum, val) => sum + (val - mean) ** 2, 0) / arr.length;
        }
        
        function detrend(signal) {
            const n = signal.length;
            let sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
            for (let i = 0; i < n; i++) {
                sumX += i;
                sumY += signal[i];
                sumXY += i * signal[i];
                sumX2 += i * i;
            }
            const slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
            const intercept = (sumY - slope * sumX) / n;
            return signal.map((v, i) => v - (slope * i + intercept));
        }
        
        // Autocorrelation-based BPM estimation
        function estimateBPMAutocorr(signal, sampleRate) {
            const n = signal.length;
            if (n < 60) return null;
            
            // Min/max lag for 42-200 BPM
            const minLag = Math.floor(sampleRate * 60 / 200);
            const maxLag = Math.ceil(sampleRate * 60 / 42);
            
            let bestLag = minLag;
            let bestCorr = -Infinity;
            
            // Compute autocorrelation
            for (let lag = minLag; lag <= Math.min(maxLag, n / 2); lag++) {
                let corr = 0;
                let count = 0;
                for (let i = 0; i < n - lag; i++) {
                    corr += signal[i] * signal[i + lag];
                    count++;
                }
                corr /= count;
                
                if (corr > bestCorr) {
                    bestCorr = corr;
                    bestLag = lag;
                }
            }
            
            const period = bestLag / sampleRate;
            return 60 / period;
        }
        
        // Draw signal visualization
        function drawSignal() {
            const ctx = signalCtx;
            const w = signalCanvas.width;
            const h = signalCanvas.height;
            
            ctx.fillStyle = 'rgba(15, 15, 26, 0.4)';
            ctx.fillRect(0, 0, w, h);
            
            const signal = filteredSignal.length > 0 ? filteredSignal : rawSignal;
            if (signal.length < 2) return;
            
            const min = Math.min(...signal);
            const max = Math.max(...signal);
            const range = max - min || 1;
            
            // Waveform
            ctx.beginPath();
            ctx.strokeStyle = '#ff6b6b';
            ctx.lineWidth = 2;
            
            for (let i = 0; i < signal.length; i++) {
                const x = (i / signal.length) * w;
                const y = h - ((signal[i] - min) / range) * h * 0.8 - h * 0.1;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            ctx.stroke();
            
            // Zero line
            ctx.strokeStyle = 'rgba(255,255,255,0.1)';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(0, h / 2);
            ctx.lineTo(w, h / 2);
            ctx.stroke();
        }
        
        // Initial setup
        resizeCanvases();
        drawSignal();
    </script>
</body>
</html>
